from __future__ import division
from sklearn.cross_validation import train_test_split
from sklearn.cross_validation import LeaveOneOut
from sklearn.neural_network import BernoulliRBM
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.grid_search import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.lda import LDA
from sklearn.qda import QDA
from matplotlib import pyplot
import codecs, copy, inspect

def get_parameter_grid(classifier_name):
	
	if classifier_name == "SVC":
		param_grid = [{
		'C'                         :[1 + n*10 for n in xrange(3)],
		'kernel'                    :["linear","poly","rbf","sigmoid"],
		'degree'                    :[1 + 3*n for n in xrange(2)],
		'gamma'                     :[.1 + (.3*n) for n in xrange(3)],
		'probability'               :[True, False],
		'shrinking'                 :[True,False],
		'tol'                       :[0.00001 + (i * 10) for i in xrange(4)],
		'cache_size'                :[0.00001 + (i * 10) for i in xrange(4)],
		}]
	
	elif classifier_name == "DecisionTreeClassifier":
		param_grid = [{
		'criterion'                 :["gini","entropy"],
		'splitter'                  :["best","random"],
		'max_features'              :["auto","sqrt","log2",None],
		'max_features'              :[1 + (n) for n in xrange(3)],
		'max_depth'                 :[1 + (10*n) for n in xrange(3)],
		'min_samples_split'         :[1 + (10*n) for n in xrange(3)],
		'min_samples_leaf'          :[1 + (10*n) for n in xrange(3)],
		}]
	
	elif classifier_name == "KNeighborsClassifier":
		param_grid = [{
		'n_neighbors'               :[1 + (n) for n in xrange(10)],
		'algorithm'                 :['ball_tree','kd_tree','brute'],
		'leaf_size'                 :[1 + (n*3) for n in xrange(4)],
		'p'                         :[2 + (n*5) for n in xrange(5)],
		}]
	
	elif classifier_name == "LDA":
		param_grid = [{
		#'solver'                   :["svd","lsqr","eigen"],
		#'tol'                      :[0.000001 + (i * 10) for i in xrange(6)],
		#'store_covariance'         :[True,False]
		#'shrinkage'                :[None, 'auto', .1,.2,.3,.4,.5,.6,.7,.8,.9]
		}]
	
	elif classifier_name == "QDA":
		param_grid = [{
		'reg_param'                 :[.0001 + (10*n) for n in xrange(6)],
		}]

	elif classifier_name == "RandomForestClassifier":
		param_grid = [{
		'n_estimators'              :[1 + (10*n) for n in xrange(4)],
		'criterion'                 :["gini","entropy"],
		'max_features'              :[1 + (n) for n in xrange(4)],
		'max_depth'                 :[1 + (10*n) for n in xrange(4)],
		'min_samples_split'         :[1 + (10*n) for n in xrange(4)],
		'min_samples_leaf'          :[1 + (10*n) for n in xrange(4)],
		'bootstrap'                 :[True],
		'oob_score'                 :[True,False],
		#'min_weight_fraction_leaf' :[.001 + (10*n) for n in xrange(6)],
		#'warm_start'               :[True,False],
		}]
		
	elif classifier_name == "LogisticRegression":
		param_grid = [{
		'penalty'                   :["l1","l2"], 
		'dual'                      :[False], 
		'tol'                       :[0.000001 + (i * 10) for i in xrange(6)], 
		'C'                         :[0.1 + (.5 * i) for i in xrange(6)], 
		'fit_intercept'             :[True, False], 
		'intercept_scaling'         :[.1 + (.5 * i) for i in xrange(6)], 
		'class_weight'              :[None], 
		'random_state'              :[None], 
		#'solver'                   :["newton-cg", "liblinear", "lbfgs"], 
		#'multi_class'              :["ovr", "multinomial"], 
		}]
		
	else:
		return None
	
	return param_grid

	
def run_grid_search(classifier, X, y):
	'''Run grid search over classifier parameters and return optimal parameters in dictionary form'''
	
	#retrieve current classifier name in order to retrieve relevant parameter grid
	classifier_name = str(classifier).split("(")[0]
	
	param_grid = get_parameter_grid(classifier_name)
	
	if param_grid is not None:
		X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)
		scores = ["precision", "recall"]
		
		#we set cv to 50 for 50 fold cross validation (or leave one out); verbose sets the level of output generated by the grid search
		grid_search_classifier = GridSearchCV(classifier, param_grid, cv=25, verbose=1)
		grid_search_classifier.fit(X, y)
		
		print grid_search_classifier.best_params_
		print grid_search_classifier.best_score_
	
	
def measure_accuracy(tp,fp,tn,fn):
	'''Read in true positives, false positives, true negatives, and false negatives, and return the precision, recall, f1, and accuracy measures'''
	accuracy  = (tp+tn) / (tp+fp+tn+fn)
	precision = tp / (tp+fp)
	recall    = tp / (tp+fn)
	f_score   = 2*( (precision*recall) / (precision+recall) )
	return (accuracy, precision, recall, f_score)
	
delimiter = "\t"

with codecs.open("aggregated_goldsmith_features.txt","r","utf-8") as goldy:
    
	goldy = goldy.read().replace("\r","").split("\n")[1:-1]
	
	#populate a list of classifiers 
	support_vector_c      = SVC(C=1)
	decision_tree_c       = DecisionTreeClassifier(max_depth=5) #with 4 features, depth of 2 is best; with 6 features depth of 4
	nearest_neighbors_c   = KNeighborsClassifier(6)
	naive_bayes_c         = GaussianNB()
	lda_c                 = LDA()
	qda_c                 = QDA()
	random_forests_c      = RandomForestClassifier(max_features=2, max_depth=2)
	ada_boost_c           = AdaBoostClassifier()
	logistic_regression_c = LogisticRegression()
	
	for classifier in [support_vector_c, decision_tree_c, nearest_neighbors_c, naive_bayes_c, lda_c, qda_c, random_forests_c, logistic_regression_c]:

		#each time you load a new classifier, reset all predictions values to zero with this little trick
		tp, fp, tn, fn = (0,)*4
		
		for i in xrange(50):

			goldy_copy = copy.copy(goldy)
        
			#this line simultaneously removes index position i from goldy_copy and stores that value in row_to_test, perfect for hold one out evaluation
			row_to_test      = goldy_copy.pop(i)
			
			test_groundtruth = row_to_test.split(delimiter)[-1]
			row_to_test      = [float(value) for value in row_to_test.split(delimiter)[:-1]]
        
			training_features = [[float(value) for value in row.split(delimiter)[:-1]] for row in goldy_copy]
			groundtruth = [float(value) for row in goldy_copy for value in row.split(delimiter)[-1]]
        
			#x is a list of sublists, each sublist of which is an ordered array of four features
			X = training_features
        
			#y is a list of the groundtruth values for each row in the infile
			y = groundtruth
			
			#prepare classifier
			clf = classifier
			clf.fit(X, y)

			prediction = clf.predict( row_to_test )

			#prediction[0] contains the value of prediction
			if float(prediction[0]) == float(test_groundtruth):						
				if test_groundtruth == "1":
					tp += 1
				else:
					tn += 1
			else:
				if test_groundtruth == "0":
					fp += 1
				else:
					fn += 1
					
		accuracy_results = measure_accuracy(tp,fp,tn,fn)
		
		#run_grid_search(classifier, X, y)
		
		#retrieve classifier name and all accuracy measures
		classifier = str(classifier).split("(")[0]       
		
		'''
		print classifier, "tp", tp
		print classifier, "fp", fp
		print classifier, "tn", tn
		print classifier, "fn", fn
		'''
		
		print classifier, "accuracy",  accuracy_results[0]
		print classifier, "precision", accuracy_results[1]
		print classifier, "recall",    accuracy_results[2]
		print classifier, "f_score",   accuracy_results[3]
